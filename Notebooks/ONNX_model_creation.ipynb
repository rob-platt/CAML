{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from crism_classifier.VAE_classifier_248 import EncoderX, EncoderY, DecoderX, Classifier, Prior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAEClassifier(nn.Module):\n",
    "    def __init__(\n",
    "        self, n_blocks=3, n_conv_layers=1, zx_dim=16, zy_dim=16, n_classes=38\n",
    "    ):\n",
    "        \"\"\"Hybrid VAE and Classifier network.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        n_blocks : int\n",
    "            Number of convolutional up and downsampling blocks\n",
    "            in the encoder and decoder.\n",
    "            Must be at least 1, and less than 6.\n",
    "            Default = 3.\n",
    "        n_conv_layers : int\n",
    "            Number of convolutional blocks between each downsampling block.\n",
    "            Default is 1.\n",
    "        zx_dim : int\n",
    "            Dimension of the noisy/entangled latent space.\n",
    "            Default is 16.\n",
    "        zy_dim : int\n",
    "            Dimension of the clean/disentangled latent space.\n",
    "            Default is 16.\n",
    "        n_classes : int\n",
    "            Number of classes to predict.\n",
    "            Default is 37.\n",
    "        \"\"\"\n",
    "        super(VAEClassifier, self).__init__()\n",
    "        self.n_blocks = n_blocks\n",
    "        self.n_conv_layers = n_conv_layers\n",
    "        self.zx_dim = zx_dim\n",
    "        self.zy_dim = zy_dim\n",
    "        self.n_classes = n_classes\n",
    "\n",
    "        self.encoder_x = EncoderX(\n",
    "            self.n_blocks, self.n_conv_layers, self.zx_dim\n",
    "        )\n",
    "        self.encoder_y = EncoderY(\n",
    "            self.n_blocks, self.n_conv_layers, self.zy_dim\n",
    "        )\n",
    "        self.decoder = DecoderX(\n",
    "            self.n_blocks, self.n_conv_layers, self.zx_dim + self.zy_dim\n",
    "        )\n",
    "        self.classifier = Classifier(self.n_classes, self.zy_dim)\n",
    "        self.prior_x = Prior(self.zx_dim)\n",
    "        self.prior_y = Prior(self.zy_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"Run a full forward pass on input x.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        x : torch.Tensor\n",
    "            Input spectra to run through the network.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        x_recon : torch.Tensor\n",
    "            Reconstructed input spectra.\n",
    "        y_pred : torch.Tensor\n",
    "            Predicted mineral class probabilities.\n",
    "        \"\"\"\n",
    "        mu_e_x, log_var_e_x = self.encoder_x(x)\n",
    "        mu_e_y, log_var_e_y = self.encoder_y(x)\n",
    "        zx = mu_e_x + torch.exp(0.5 * log_var_e_x) * torch.randn_like(mu_e_x)\n",
    "        zy = mu_e_y + torch.exp(0.5 * log_var_e_y) * torch.randn_like(mu_e_y)\n",
    "        x_recon = self.decoder(zx, zy)\n",
    "        y_pred = self.classifier(mu_e_y)\n",
    "        y_pred = F.softmax(y_pred, dim=1)\n",
    "        return x_recon, y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_x = torch.randn(1024, 1, 248)\n",
    "\n",
    "model = VAEClassifier(n_blocks=1, n_conv_layers=1, zx_dim=16, zy_dim=16, n_classes=38)\n",
    "model.load_state_dict(torch.load(\"/home/rob_platt/CRISM_classifier_application/data/v3_248_1_1_zx16_zy16_beta20_epoch100_weights.pth\", map_location=torch.device('cpu')))\n",
    "model.eval()\n",
    "\n",
    "x_recon, y_pred = model(rand_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================ Diagnostic Run torch.onnx.export version 2.0.1 ================\n",
      "verbose: False, log level: Level.ERROR\n",
      "======================= 0 NONE 0 NOTE 0 WARNING 0 ERROR ========================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "onnx_program = torch.onnx.export(model, rand_x, \"vae_classifier_1024.onnx\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pixel_class_breakable",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
